# yaml-language-server: $schema=./json_schema/sibytes_yetl_pipeline_schema.json

version: 2.0.3
# paths here are relative to this configuration document
tables: ./tables.yaml

audit_control:
  delta_lake:
    # delta table properties can be set at stage level or table level
    delta_properties:
        delta.appendOnly: true
        delta.autoOptimize.autoCompact: true
        delta.autoOptimize.optimizeWrite: true
    managed: false
    container: datalake
    location: /mnt/{{container}}/data
    path: "{{database}}/{{table}}"
    options:
      checkpointLocation: "/mnt/{{container}}/checkpoint/{{project}}/{{checkpoint}}"

landing:
  read:
    trigger: customerdetailscomplete-{{filename_date_format}}*.flg
    trigger_type: file
    database: "{{database}}"
    table: "{{table}}"
    container: landing
    location: "/mnt/{{container}}/data/{{project}}/{{table}}/*"
    filename: "{{table}}-*.csv"
    filename_date_format: "%Y%m%d"
    path_date_format: "%Y%m%d"
    format: cloudFiles
    spark_schema: ../schema/{{table.lower()}}.yaml
    options:
      # autoloader
      cloudFiles.format: csv
      cloudFiles.schemaLocation:  /mnt/{{container}}/checkpoint/{{project}}/{{checkpoint}}
      cloudFiles.useIncrementalListing: auto
      # schema
      inferSchema: false
      enforceSchema: true
      columnNameOfCorruptRecord: _corrupt_record
      # csv
      header: false
      mode: PERMISSIVE
      encoding: windows-1252
      delimiter: ","
      escape: '"'
      nullValue: ""
      quote: '"'
      emptyValue: ""
    

raw:
  delta_lake:
    database: "{{database}}"
    table: "{{table}}"
    container: datalake
    location: /mnt/{{container}}/data
    path: "{{database}}/{{table}}"
    z_order_by:
      - _load_date
    options:
      mergeSchema: true
      checkpointLocation: "/mnt/{{container}}/checkpoint/{{project}}/{{checkpoint}}"
        # optional leave it out if you don't want them
    warning_thresholds:
      invalid_rows: 0
    # optional leave it out if you don't want them
    exception_thresholds:
      invalid_rows: 2


base:
  delta_lake:
    database: "{{database}}"
    table: "{{table}}"
    container: datalake
    location: /mnt/{{container}}/data
    path: "{{database}}/{{table}}"
    options: null
